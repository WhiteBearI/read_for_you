<template>
	<div class="container">
		<!-- é¡¶éƒ¨å¯¼èˆªæ  -->
		<TopNav :show-language-switcher="false">
			<template #center>
				<span class="page-indicator">AI Chat</span>
			</template>
		</TopNav>

		<div class="content">
			<!-- è¿”å›é˜…è¯»é¡µé¢æŒ‰é’® - å·¦ä¸Šè§’ -->
			<button ref="backButtonRef" class="back-btn-corner" tabindex="2" @click="goBackToReading" :aria-label="t('backToReadingPage')">
				<svg width="24" height="24" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg" aria-hidden="true">
					<path d="M19 12H5M12 19l-7-7 7-7" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/>
				</svg>
			</button>

			<!-- å›ºå®šçš„å›¾ç‰‡åŒºåŸŸ -->
			<div class="target-image" aria-hidden="true">
				<img :src="targetImage" alt="" tabindex="-1" />
			</div>

			<!-- å¯æ»šåŠ¨çš„èŠå¤©åŒºåŸŸ -->
			<div class="chat-area" ref="chatAreaRef">
				<!-- AI æè¿°åŒºåŸŸ -->
				<div v-if="imageDescription" class="ai-description-box" aria-hidden="true">
					<div class="ai-badge">ğŸ¤– {{ t('aiDescription') }}</div>
					<p class="ai-description-text" tabindex="-1">{{ imageDescription }}</p>
				</div>
				<div v-for="(message, index) in messages" :key="index">
					<UserMessage 
						v-if="message.role === 'user'" 
						:seq="index" 
						:duration="message.duration"
						:isPlaying="currentPlayingIndex === index"
						@play="handlePlayAudio(index)" />
					<AIMessage 
						v-else 
						:ref="el => setAIMessageRef(el, index)"
						:seq="index" 
						:duration="message.duration"
						:isPlaying="currentPlayingIndex === index"
						@play="handlePlayAudio(index)" />
				</div>
			</div>
			<div class="control-area">
				<!-- Connection error message -->
				<div v-if="connectionError" class="connection-error">
					âš ï¸ {{ connectionError }}
				</div>
				<button
					ref="talkButtonRef"
					class="talk-button"
					tabindex="1"
					:class="{ 'is-recording': isRecording }"
					:disabled="!isWebSocketReady || connectionError"
					@mousedown="startRecording"
					@mouseup="stopRecording"
					@keydown.space.prevent="startRecording"
					@keyup.space.prevent="stopRecording">
					{{ isWebSocketReady ? t('holdToTalk') : 'Connecting...' }}
				</button>
			</div>
		</div>
	</div>
</template>

<script setup>
import { ref, onMounted, onUnmounted, nextTick } from 'vue'
const aiChatUrl = import.meta.env.VITE_AI_CHAT_URL;
import UserMessage from './UserMessage.vue';
import AIMessage from './AIMessage.vue';
import { useTranslation, addLanguageParam } from '../../utils/i18n.js';
import TopNav from '../TopNav.vue';
import indexedDBService from '../../utils/IndexedDBService.js';

const { t } = useTranslation();

const messages = ref([])
const imageDescription = ref('') // AIç”Ÿæˆçš„å›¾ç‰‡æè¿°
const useChunkedAudioSend = true // åˆ‡æ¢ true ä½¿ç”¨åˆ†ç‰‡å‘é€ï¼›false ä½¿ç”¨åŸå…ˆæ•´æ®µ base64 ä¸€æ¬¡æ€§å‘é€
const targetImage = ref(null)
const chatAreaRef = ref(null)
const talkButtonRef = ref(null)
const backButtonRef = ref(null)
const aiMessageRefs = ref({})
const isRecording = ref(false)
const currentPlayingIndex = ref(null) // å½“å‰æ­£åœ¨æ’­æ”¾çš„æ¶ˆæ¯ç´¢å¼•
const isWebSocketReady = ref(false) // WebSocket connection status
const connectionError = ref(null) // Connection error message

let messageCounter = 0;
let ws = null
let audioContext = null
let mediaStream = null
let mediaRecorder = null
let playingSource = null // å½“å‰æ­£åœ¨æ’­æ”¾çš„éŸ³é¢‘æº
let startTime = null
let endTime = null

function connectWS() {
	return new Promise((resolve, reject) => {
		const wsUrlWithLang = addLanguageParam(aiChatUrl);
		console.log('[connectWS] Connecting to:', wsUrlWithLang);
		ws = new window.WebSocket(wsUrlWithLang);
		ws.binaryType = 'blob';

		// Timeout after 10 seconds
		const timeout = setTimeout(() => {
			if (ws.readyState !== WebSocket.OPEN) {
				connectionError.value = 'Connection timeout. Please refresh the page.';
				reject(new Error('WebSocket connection timeout'));
			}
		}, 10000);

		ws.onopen = () => {
			clearTimeout(timeout);
			console.log('[WebSocket] âœ“ Connected successfully');
			console.log('[WebSocket] readyState:', ws.readyState, '(1 = OPEN)');
			isWebSocketReady.value = true;
			connectionError.value = null;
			resolve();
		};

		ws.onerror = (error) => {
			clearTimeout(timeout);
			console.error('[WebSocket] âŒ Error:', error);
			connectionError.value = 'Connection failed. Please check your network.';
			reject(error);
		};

		ws.onclose = (event) => {
			console.log('[WebSocket] âš  Connection closed');
			console.log('[WebSocket] Code:', event.code, 'Reason:', event.reason);
			isWebSocketReady.value = false;
		};

		// Log any messages received (for debugging)
		ws.onmessage = (event) => {
			console.log('[WebSocket] â† Received raw message:', event.data.substring(0, 200));
		};
	});
}

async function parseHashImage() {
	let storedBase64 = null
	let storedDescription = null
	try {
		// ä» IndexedDB è¯»å–å›¾ç‰‡ base64 æ•°æ®ï¼ˆå·²ç”± ReadingPage é¢„å…ˆä¸‹è½½ï¼‰
		storedBase64 = await indexedDBService.getItem('selectedImageBase64')
		storedDescription = await indexedDBService.getItem('selectedImageDescription')
	} catch (err) {
		console.warn('Failed to read image data from IndexedDB:', err)
	}
	if (storedBase64) {
		targetImage.value = storedBase64
		console.log('ğŸ“· Loaded image base64 from IndexedDB')
		if (storedDescription) {
			imageDescription.value = storedDescription
			console.log('ğŸ“ Loaded AI description:', storedDescription)
		}
		return
	}
}

// è¿”å›é˜…è¯»é¡µé¢
function goBackToReading() {
	window.location.hash = '#/reading';
}

async function initRecorder() {
	try {
		const mediaStream = await navigator.mediaDevices.getUserMedia({ audio: true })
		navigator.permissions.query({ name: 'microphone' }).then(result => {
			console.log('éº¦å…‹é£æƒé™çŠ¶æ€:', result.state); // "granted", "denied", "prompt"
		});
		mediaRecorder = new MediaRecorder(mediaStream, { mimeType: 'audio/webm' })
		mediaRecorder.ondataavailable = (e) => {
			if (e.data && e.data.size > 0) {
				addMessage("user", endTime - startTime, e.data);
				handleResponse(e.data)
			}
		}
	} catch (error) {
		console.log("Record initialization failed, fail reason: " + error)
	}
}

function startRecording(event) {
	// å¤„ç†ç©ºæ ¼é”®æˆ–é¼ æ ‡æŒ‰ä¸‹
	if (event.type === 'mousedown' || (event.type === 'keydown' && event.key === ' ' && !event.repeat)) {
		// å¦‚æœæ­£åœ¨æ’­æ”¾éŸ³é¢‘ï¼Œå…ˆåœæ­¢æ’­æ”¾
		if (currentPlayingIndex.value !== null) {
			stopCurrentAudio();
		}
		isRecording.value = true;
		mediaRecorder.start();
		startTime = performance.now();
	}
}

function stopRecording(event) {
	// å¤„ç†ç©ºæ ¼é”®æˆ–é¼ æ ‡é‡Šæ”¾
	if (event.type === 'mouseup' || (event.type === 'keyup' && event.key === ' ')) {
		isRecording.value = false;
		mediaRecorder.stop();
		endTime = performance.now();
	}
}

function addMessage(role, duration, data) {
	const newIndex = messages.value.length;
	messages.value.push({
		"role": role,
		"duration": duration,
		"data": data
	});
	// æ·»åŠ æ¶ˆæ¯åè‡ªåŠ¨æ»šåŠ¨åˆ°åº•éƒ¨
	scrollToBottom();
	// å¦‚æœæ˜¯AIæ¶ˆæ¯ï¼Œè‡ªåŠ¨æ’­æ”¾
	if (role === 'assistant') {
		nextTick(() => {
			handlePlayAudio(newIndex);
		});
	}
}

// è®¾ç½®AIæ¶ˆæ¯çš„ref
function setAIMessageRef(el, index) {
	if (el) {
		aiMessageRefs.value[index] = el;
	}
}

// èšç„¦åˆ°æœ€æ–°çš„AIæ¶ˆæ¯
function focusLatestAIMessage(index) {
	const aiMessageComponent = aiMessageRefs.value[index];
	if (aiMessageComponent && aiMessageComponent.$el) {
		const bubble = aiMessageComponent.$el.querySelector('.voice-bubble');
		if (bubble) {
			bubble.tabIndex = 3;
			bubble.focus();
		}
	}
}

function scrollToBottom() {
	nextTick(() => {
		if (chatAreaRef.value) {
			chatAreaRef.value.scrollTop = chatAreaRef.value.scrollHeight;
		}
	});
}

function createMessage(msgType, data, requestId = null) {
	const messageId = generateMessageId();
	const timestamp = new Date().toISOString();
	const message = {
		message_id: messageId,
		timestamp: timestamp,
		type: msgType,
		data: data
	};

	if (requestId) {
		message.request_id = requestId;
	}

	return message;
}

function generateMessageId() {
	messageCounter += 1;
	return 'msg_' + String(messageCounter).padStart(3, '0');
}

function sendMessage(message) {
	if (!ws || ws.readyState !== WebSocket.OPEN) {
		throw new Error('Not connected to WebSocket')
	}
	try {
		const json = JSON.stringify(message)
		ws.send(json)
	} catch (err) {
		console.error('sendMessage failed:', err)
	}
}

// å°†éŸ³é¢‘ Blob è½¬æ¢ä¸º WAV æ ¼å¼
async function convertToWav(audioBlob) {
	console.log('[convertToWav] Converting audio to WAV format...');
	console.log('[convertToWav] Input blob size:', audioBlob.size, 'type:', audioBlob.type);
	
	try {
		// 1. è¯»å–éŸ³é¢‘æ•°æ®
		const arrayBuffer = await audioBlob.arrayBuffer();
		
		// 2. ä½¿ç”¨ AudioContext è§£ç éŸ³é¢‘
		const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);
		console.log('[convertToWav] Decoded audio:', {
			duration: audioBuffer.duration,
			sampleRate: audioBuffer.sampleRate,
			numberOfChannels: audioBuffer.numberOfChannels,
			length: audioBuffer.length
		});
		
		// 3. æå–éŸ³é¢‘æ•°æ® (è½¬æ¢ä¸ºå•å£°é“)
		const numberOfChannels = 1; // è½¬ä¸ºå•å£°é“
		const sampleRate = audioBuffer.sampleRate;
		const length = audioBuffer.length;
		
		// è·å–éŸ³é¢‘æ•°æ® (å¦‚æœæ˜¯å¤šå£°é“,æ··åˆæˆå•å£°é“)
		let audioData;
		if (audioBuffer.numberOfChannels === 1) {
			audioData = audioBuffer.getChannelData(0);
		} else {
			// æ··åˆå¤šå£°é“ä¸ºå•å£°é“
			audioData = new Float32Array(length);
			for (let i = 0; i < length; i++) {
				let sum = 0;
				for (let channel = 0; channel < audioBuffer.numberOfChannels; channel++) {
					sum += audioBuffer.getChannelData(channel)[i];
				}
				audioData[i] = sum / audioBuffer.numberOfChannels;
			}
		}
		
		// 4. è½¬æ¢ä¸º 16 ä½ PCM
		const pcmData = new Int16Array(audioData.length);
		for (let i = 0; i < audioData.length; i++) {
			// å°†æµ®ç‚¹æ•° [-1, 1] è½¬æ¢ä¸º 16 ä½æ•´æ•° [-32768, 32767]
			const s = Math.max(-1, Math.min(1, audioData[i]));
			pcmData[i] = s < 0 ? s * 0x8000 : s * 0x7FFF;
		}
		
		// 5. æ·»åŠ  WAV æ–‡ä»¶å¤´
		const wavData = addWavHeader(new Uint8Array(pcmData.buffer), sampleRate, numberOfChannels, 16);
		const wavBlob = new Blob([wavData], { type: 'audio/wav' });
		
		console.log('[convertToWav] âœ“ Conversion complete');
		console.log('[convertToWav] Output WAV size:', wavBlob.size, 'bytes');
		
		return wavBlob;
	} catch (error) {
		console.error('[convertToWav] âŒ Conversion failed:', error);
		// å¦‚æœè½¬æ¢å¤±è´¥,è¿”å›åŸå§‹ blob
		console.warn('[convertToWav] Returning original blob');
		return audioBlob;
	}
}

async function sendAudio(audioBlob, requestId) {
	console.log('\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”');
	console.log('â”‚ [sendAudio] START                               â”‚');
	console.log('â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜');
	console.log('[sendAudio] Original blob size:', audioBlob.size, 'type:', audioBlob.type);
	console.log('[sendAudio] Request ID:', requestId);
	
	if (!ws || ws.readyState !== WebSocket.OPEN) {
		console.error('[sendAudio] âŒ WebSocket not connected!');
		throw new Error('Not connected to WebSocket');
	}
	console.log('[sendAudio] âœ“ WebSocket is OPEN');

	// è½¬æ¢ä¸º WAV æ ¼å¼
	console.log('[sendAudio] â†’ Converting to WAV format...');
	const wavBlob = await convertToWav(audioBlob);
	console.log('[sendAudio] âœ“ Converted to WAV, size:', wavBlob.size);

	const audioData = new Uint8Array(await wavBlob.arrayBuffer());
	const fileSize = audioData.length;
	const filename = 'recording.wav';
	const fileFormat = 'wav';
	
	// Convert to base64
	const audioBase64 = uint8ToBase64(audioData);
	
	// Calculate estimated message size
	const testMessage = {
		input_type: "audio",
		content: audioBase64,
		metadata: { 
			filename: filename, 
			size: fileSize, 
			format: fileFormat 
		}
	};
	const estimatedMessageSize = JSON.stringify(testMessage).length + 200; // Account for message wrapper
	
	console.log('[sendAudio] File size:', fileSize, 'bytes');
	console.log('[sendAudio] Estimated message size:', estimatedMessageSize, 'bytes');
	
	// Check if file needs chunking (800KB threshold, leave buffer for 1MB limit)
	if (estimatedMessageSize > 800000) {
		console.log('[sendAudio] âš  Large file detected, using chunking...');
		await sendAudioChunked(audioData, filename, fileFormat, requestId);
	} else {
		console.log('[sendAudio] â†’ Sending as single message...');
		// Send as single message
		const audioMsg = createMessage("request", {
			input_type: "audio",
			content: audioBase64,
			metadata: {
				filename: filename,
				size: fileSize,
				format: fileFormat,
				is_final: true
			}
		}, requestId);
		
		await sendMessage(audioMsg);
		console.log(`[sendAudio] âœ“ Sent audio file: ${filename} (${fileSize} bytes)`);
		
		// Wait for acknowledgment
		console.log('[sendAudio] â³ Waiting for ACK...');
		try {
			const response = await receiveMessage();
			console.log('[sendAudio] â† Received ACK response:', response);
			
			if (response.type === "ack" && response.data?.status?.includes("input_received")) {
				console.log('[sendAudio] âœ“ Audio input acknowledged');
			} else {
				console.log('[sendAudio] âš  Unexpected response:', response);
			}
		} catch (err) {
			console.error('[sendAudio] âŒ Failed to receive acknowledgment:', err);
			throw err;
		}
	}
	
	console.log('â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”');
	console.log('â”‚ [sendAudio] COMPLETED                           â”‚');
	console.log('â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n');
}

async function sendAudioChunked(audioData, filename, fileFormat, requestId, chunkSize = 500000) {
	console.log('[sendAudioChunked] Starting chunked send...');

	const totalSize = audioData.length;
	const totalChunks = Math.ceil(totalSize / chunkSize);
	
	console.log(`[sendAudioChunked] Total chunks: ${totalChunks}, chunk size: ${chunkSize}`);
	
	for (let i = 0; i < totalChunks; i++) {
		const start = i * chunkSize;
		const end = Math.min(start + chunkSize, totalSize);
		const chunk = audioData.subarray(start, end);
		const chunkBase64 = uint8ToBase64(chunk);
		const isFinal = (i === totalChunks - 1);
		
		const chunkMsg = createMessage("request", {
			input_type: "audio",
			content: chunkBase64,
			metadata: {
				filename: filename,
				size: totalSize,        // â† æ·»åŠ æ€»å¤§å°
				format: fileFormat,
				is_final: isFinal,
				chunk_index: i,
				total_chunks: totalChunks
			}
		}, requestId);
		
		await sendMessage(chunkMsg);
		console.log(`âœ“ Sent chunk ${i + 1}/${totalChunks} (${chunk.length} bytes)`);
		
		// Wait for acknowledgment of EACH chunk (not just the last one)
		try {
			const response = await receiveMessage();
			console.log(`[sendAudioChunked] Chunk ${i + 1} response:`, response);
			
			if (response.type === "ack" && response.data?.status?.includes("input_received")) {
				console.log(`âœ“ Chunk ${i + 1} acknowledged`);
			} else {
				console.log(`âš  Unexpected response for chunk ${i + 1}:`, response);
			}
		} catch (err) {
			console.error(`[sendAudioChunked] Failed to receive acknowledgment for chunk ${i + 1}:`, err);
		}
	}
	
	console.log(`âœ“ Completed sending ${totalChunks} chunks (${totalSize} bytes total)`);
}

function uint8ToBase64(uint8Array) {
	let binary = '';
	const len = uint8Array.byteLength;
	for (let i = 0; i < len; i++) {
		binary += String.fromCharCode(uint8Array[i]);
	}
	return btoa(binary);
}

// ä¸ºåŸå§‹ PCM æ•°æ®æ·»åŠ  WAV æ–‡ä»¶å¤´
function addWavHeader(pcmData, sampleRate = 24000, numChannels = 1, bitsPerSample = 16) {
	const dataLength = pcmData.length;
	const buffer = new ArrayBuffer(44 + dataLength);
	const view = new DataView(buffer);
	
	// RIFF æ ‡è¯†ç¬¦
	writeString(view, 0, 'RIFF');
	// æ–‡ä»¶å¤§å°
	view.setUint32(4, 36 + dataLength, true);
	// WAVE æ ‡è¯†ç¬¦
	writeString(view, 8, 'WAVE');
	// fmt å­å—
	writeString(view, 12, 'fmt ');
	// fmt å­å—å¤§å°
	view.setUint32(16, 16, true);
	// éŸ³é¢‘æ ¼å¼ (1 = PCM)
	view.setUint16(20, 1, true);
	// å£°é“æ•°
	view.setUint16(22, numChannels, true);
	// é‡‡æ ·ç‡
	view.setUint32(24, sampleRate, true);
	// å­—èŠ‚ç‡ (é‡‡æ ·ç‡ * å£°é“æ•° * ä½æ·±åº¦/8)
	view.setUint32(28, sampleRate * numChannels * (bitsPerSample / 8), true);
	// å—å¯¹é½ (å£°é“æ•° * ä½æ·±åº¦/8)
	view.setUint16(32, numChannels * (bitsPerSample / 8), true);
	// ä½æ·±åº¦
	view.setUint16(34, bitsPerSample, true);
	// data å­å—
	writeString(view, 36, 'data');
	// data å­å—å¤§å°
	view.setUint32(40, dataLength, true);
	
	// å†™å…¥ PCM æ•°æ®
	const pcmView = new Uint8Array(buffer, 44);
	pcmView.set(pcmData);
	
	return new Uint8Array(buffer);
}

function writeString(view, offset, string) {
	for (let i = 0; i < string.length; i++) {
		view.setUint8(offset + i, string.charCodeAt(i));
	}
}

async function getAudioDuration(blob, sampleRate = 24000, channels = 1, bitsPerSample = 16) {
	console.log('[getAudioDuration] Input params:', { 
		blobSize: blob.size, 
		blobType: blob.type,
		sampleRate, 
		channels, 
		bitsPerSample 
	});
	
	// æ£€æŸ¥ blob æ˜¯å¦ä¸ºç©º
	if (!blob || blob.size === 0) {
		console.error('[getAudioDuration] âŒ Empty blob!');
		return 0;
	}
	
	try {
		const arrayBuffer = await blob.arrayBuffer();
		console.log('[getAudioDuration] ArrayBuffer size:', arrayBuffer.byteLength);
		
		// å†æ¬¡æ£€æŸ¥æ•°æ®æ˜¯å¦ä¸ºç©º
		if (arrayBuffer.byteLength === 0) {
			console.error('[getAudioDuration] âŒ Empty arrayBuffer!');
			return 0;
		}
		
		const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);
		console.log('[getAudioDuration] âœ“ Successfully decoded, duration:', audioBuffer.duration);
		console.log('[getAudioDuration] AudioBuffer info:', {
			duration: audioBuffer.duration,
			length: audioBuffer.length,
			sampleRate: audioBuffer.sampleRate,
			numberOfChannels: audioBuffer.numberOfChannels
		});
		
		// å¦‚æœè§£ç æˆåŠŸä½† duration ä¸º 0ï¼Œä½¿ç”¨ä¼°ç®—æ–¹å¼
		if (audioBuffer.duration === 0 && arrayBuffer.byteLength > 44) {
			const bytesPerSecond = sampleRate * channels * (bitsPerSample / 8);
			const estimatedDuration = (arrayBuffer.byteLength - 44) / bytesPerSecond; // å‡å» WAV å¤´çš„ 44 å­—èŠ‚
			console.log('[getAudioDuration] âš  Duration is 0, using estimated:', estimatedDuration);
			return estimatedDuration;
		}
		
		return audioBuffer.duration;
	} catch (error) {
		console.warn('[getAudioDuration] Failed to decode audio, trying with WAV header...', error);
		
		// å¦‚æœè§£ç å¤±è´¥,å°è¯•æ·»åŠ  WAV å¤´ (ä½¿ç”¨ä¼ å…¥çš„éŸ³é¢‘å‚æ•°)
		try {
			const arrayBuffer = await blob.arrayBuffer();
			const pcmData = new Uint8Array(arrayBuffer);
			
			// æ·»åŠ  WAV æ–‡ä»¶å¤´ (ä½¿ç”¨çœŸå®çš„éŸ³é¢‘å‚æ•°)
			const wavData = addWavHeader(pcmData, sampleRate, channels, bitsPerSample);
			const wavBlob = new Blob([wavData], { type: 'audio/wav' });
			const wavBuffer = await wavBlob.arrayBuffer();
			const audioBuffer = await audioContext.decodeAudioData(wavBuffer);
			
			console.log('[getAudioDuration] âœ“ Successfully decoded with WAV header, duration:', audioBuffer.duration);
			console.log('[getAudioDuration] AudioBuffer info:', {
				duration: audioBuffer.duration,
				length: audioBuffer.length,
				sampleRate: audioBuffer.sampleRate,
				numberOfChannels: audioBuffer.numberOfChannels
			});
			return audioBuffer.duration;
		} catch (retryError) {
			console.error('[getAudioDuration] âŒ Failed to decode even with WAV header:', retryError);
			// è¿”å›ä¸€ä¸ªä¼°ç®—çš„æ—¶é•¿ (åŸºäºæ•°æ®å¤§å°)
			// å­—èŠ‚ç‡ = é‡‡æ ·ç‡ * å£°é“æ•° * (ä½æ·±åº¦/8)
			const arrayBuffer = await blob.arrayBuffer();
			const bytesPerSecond = sampleRate * channels * (bitsPerSample / 8);
			const estimatedDuration = arrayBuffer.byteLength / bytesPerSecond;
			console.log('[getAudioDuration] Using estimated duration:', estimatedDuration, 'from', arrayBuffer.byteLength, 'bytes at', bytesPerSecond, 'bytes/sec');
			return estimatedDuration;
		}
	}
}

// åœæ­¢å½“å‰æ­£åœ¨æ’­æ”¾çš„éŸ³é¢‘
function stopCurrentAudio() {
	if (playingSource) {
		try {
			playingSource.stop();
		} catch (err) {
			console.log('[stopCurrentAudio] Audio already stopped');
		}
		playingSource = null;
	}
	currentPlayingIndex.value = null;
}

// å¤„ç†éŸ³é¢‘æ’­æ”¾è¯·æ±‚
async function handlePlayAudio(index) {
	console.log('[handlePlayAudio] Clicked index:', index, 'Currently playing:', currentPlayingIndex.value);
	
	// å¦‚æœç‚¹å‡»çš„æ˜¯æ­£åœ¨æ’­æ”¾çš„éŸ³é¢‘,åˆ™åœæ­¢æ’­æ”¾
	if (currentPlayingIndex.value === index) {
		console.log('[handlePlayAudio] Stopping current audio');
		stopCurrentAudio();
		return;
	}
	
	// åœæ­¢å½“å‰æ­£åœ¨æ’­æ”¾çš„éŸ³é¢‘(å¦‚æœæœ‰)
	if (currentPlayingIndex.value !== null) {
		console.log('[handlePlayAudio] Stopping previous audio:', currentPlayingIndex.value);
		stopCurrentAudio();
	}
	
	// æ’­æ”¾æ–°çš„éŸ³é¢‘
	console.log('[handlePlayAudio] Starting new audio:', index);
	currentPlayingIndex.value = index;
	
	try {
		const blob = messages.value[index].data;
		const arrayBuffer = await blob.arrayBuffer();
		const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);
		
		console.log('[handlePlayAudio] Decoded audio for playback:', {
			duration: audioBuffer.duration,
			length: audioBuffer.length,
			sampleRate: audioBuffer.sampleRate,
			numberOfChannels: audioBuffer.numberOfChannels
		});
		
		const source = audioContext.createBufferSource();
		source.buffer = audioBuffer;
		source.connect(audioContext.destination);
		
		// æ’­æ”¾ç»“æŸæ—¶æ¸…é™¤çŠ¶æ€
		source.onended = () => {
			console.log('[handlePlayAudio] Audio playback ended');
			if (currentPlayingIndex.value === index) {
				currentPlayingIndex.value = null;
				playingSource = null;
			}
		};
		
		playingSource = source;
		source.start();
		console.log('[handlePlayAudio] âœ“ Audio started');
	} catch (err) {
		console.error('[handlePlayAudio] âŒ Error playing audio:', err);
		currentPlayingIndex.value = null;
		playingSource = null;
	}
}

function playAudioBlob(index) {
	const blob = messages.value[index].data;
	blob.arrayBuffer().then(buf => {
		audioContext.decodeAudioData(buf).then(decoded => {
			const src = audioContext.createBufferSource()
			playingSource = src
			src.buffer = decoded
			src.connect(audioContext.destination)
			src.start()
		}).catch(err => {
			console.log("Audio processing error: " + error)
		})
	})
}

async function sendImageMessage(requestId) {
	console.log('\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”');
	console.log('â”‚ [sendImageMessage] START                        â”‚');
	console.log('â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜');
	console.log('[sendImageMessage] Request ID:', requestId);
	
	if (!targetImage.value) {
		console.warn('[sendImageMessage] âš  No image data available');
		return;
	}

	try {
		// 1. ä» targetImage æå– base64 æ•°æ® (å·²ç»æ˜¯ data:image/xxx;base64,... æ ¼å¼)
		const dataUrlMatch = targetImage.value.match(/^data:image\/(\w+);base64,(.+)$/);
		if (!dataUrlMatch) {
			throw new Error('Invalid image data format');
		}
		
		const fileFormat = dataUrlMatch[1].toLowerCase();
		const imageBase64 = dataUrlMatch[2];
		
		// 2. è®¡ç®—æ–‡ä»¶å¤§å°ï¼ˆbase64 è§£ç åçš„å­—èŠ‚æ•°ï¼‰
		const fileSize = Math.floor(imageBase64.length * 3 / 4);
		console.log('[sendImageMessage] âœ“ Image data extracted:', fileSize, 'bytes');

		// 3. ç”Ÿæˆæ–‡ä»¶å
		const filename = `image.${fileFormat === 'jpeg' ? 'jpg' : fileFormat}`;

		// 4. MIME ç±»å‹æ˜ å°„
		const mimeTypeMap = {
			jpg: 'image/jpeg',
			jpeg: 'image/jpeg',
			png: 'image/png',
			gif: 'image/gif',
			bmp: 'image/bmp',
			webp: 'image/webp'
		};
		const mimeType = mimeTypeMap[fileFormat] || `image/${fileFormat}`;

		console.log('[sendImageMessage] File info:', {
			filename,
			size: fileSize,
			format: fileFormat,
			mimeType
		});

		// 5. æ„é€ æ¶ˆæ¯
		const imageMsg = createMessage("request", {
			input_type: "image",
			content: imageBase64,
			metadata: {
				filename,
				size: fileSize,
				format: fileFormat,
				mime_type: mimeType
			}
		}, requestId);  // â† ä¼ é€’ requestId

		// 6. å‘é€æ¶ˆæ¯
		console.log('[sendImageMessage] â†’ Sending image message...');
		await sendMessage(imageMsg);
		console.log(`[sendImageMessage] âœ“ Sent image file: ${filename} (${fileSize} bytes)`);
		
		// 7. ç­‰å¾… ACK ç¡®è®¤
		console.log('[sendImageMessage] â³ Waiting for ACK...');
		try {
			const ackResponse = await receiveMessage();
			console.log('[sendImageMessage] â† Received ACK response:', ackResponse);
			
			if (ackResponse.type === "ack" && ackResponse.data?.status?.includes("input_received")) {
				console.log('[sendImageMessage] âœ“ Image input acknowledged');
			} else {
				console.log('[sendImageMessage] âš  Unexpected response:', ackResponse);
			}
		} catch (err) {
			console.error('[sendImageMessage] âŒ Failed to receive acknowledgment:', err);
			throw err;
		}
		
		console.log('â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”');
		console.log('â”‚ [sendImageMessage] COMPLETED                    â”‚');
		console.log('â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n');
	} catch (err) {
		console.error('[sendImageMessage] âŒ Error:', err);
		throw err;
	}
}

async function completeInput(requestId) {
	console.log('[completeInput] Creating control message...');
	const completeMsg = createMessage("control", {
		action: "input_complete",
		request_id: requestId
	}, requestId)
	
	console.log('[completeInput] Message to send:', JSON.stringify(completeMsg, null, 2));
	await sendMessage(completeMsg)
	console.log('[completeInput] Sent with request_id:', requestId);
	
	// Wait for processing acknowledgment
	try {
		console.log('[completeInput] Waiting for acknowledgment...');
		const response = await receiveMessage();
		console.log('[completeInput] Received response:', JSON.stringify(response, null, 2));
		
		if (response.type === "ack" && response.data?.status?.includes("inputs_received")) {
			console.log('âœ“ Processing started');
		} else {
			console.log('âš  Unexpected response:', response);
		}
	} catch (err) {
		console.error('[completeInput] Failed to receive acknowledgment:', err);
	}
}

async function receiveMessage() {
	console.log('[receiveMessage] Waiting for message...');
	if (!ws || ws.readyState !== WebSocket.OPEN) {
		console.error('[receiveMessage] WebSocket not connected');
		throw new Error("Not connected to WebSocket");
	}

	return new Promise((resolve, reject) => {
		const messageHandler = (event) => {
			try {
				const message = JSON.parse(event.data);
				console.log('[receiveMessage] Received:', {
					type: message.type,
					id: message.message_id,
					output_type: message.data?.output_type,
					is_final: message.data?.metadata?.is_final
				});
				resolve(message);
			} catch (err) {
				console.error('[receiveMessage] Parse error:', err);
				reject(err);
			}
		};

		ws.addEventListener('message', messageHandler, { once: true });
		ws.addEventListener('error', (err) => {
			console.error('[receiveMessage] WebSocket error:', err);
			reject(err);
		}, { once: true });
	});
}

async function wait_for_responses(requestId) {
	console.log('[wait_for_responses] Starting, requestId:', requestId);
	console.log('[wait_for_responses] WebSocket state:', ws?.readyState);
	
	let textResponse = null;
	let audioResponse = null;
	let audioChunks = [];
	let audioFormat = "wav";
	let audioSampleRate = 24000; // é»˜è®¤é‡‡æ ·ç‡
	let audioChannels = 1; // é»˜è®¤å£°é“æ•°
	let audioBitsPerSample = 16; // é»˜è®¤ä½æ·±åº¦
	let loopCount = 0;

	while (true) {
		loopCount++;
		console.log(`[wait_for_responses] Loop #${loopCount}`);
		
		try {
			const response = await Promise.race([
				receiveMessage(),
				new Promise((_, reject) => 
				setTimeout(() => reject(new Error('Timeout')), 60000)
				)
			]);

			console.log('[wait_for_responses] Response type:', response.type);

			if (response.type === "response") {
				const data = response.data || {};
				const outputType = data.output_type;
				console.log('[wait_for_responses] Output type:', outputType);

				if (outputType === "text") {
					textResponse = data.content || "";
					console.log(`[wait_for_responses] ğŸ“ Text response: ${textResponse.substring(0, 50)}...`);
				} else if (outputType === "audio") {
					const audioContent = data.content || "";
					const isFinal = data.metadata?.is_final || false;
					audioFormat = data.metadata?.format || "wav";
					
					// ä» metadata ä¸­è·å–éŸ³é¢‘å‚æ•°
					if (data.metadata?.sample_rate) {
						audioSampleRate = data.metadata.sample_rate;
					}
					if (data.metadata?.channels) {
						audioChannels = data.metadata.channels;
					}
					if (data.metadata?.bits_per_sample) {
						audioBitsPerSample = data.metadata.bits_per_sample;
					}

					console.log('[wait_for_responses] ğŸ”Š Audio chunk received:', {
						format: audioFormat,
						size: audioContent.length,
						isFinal: isFinal,
						chunkCount: audioChunks.length + 1,
						sampleRate: audioSampleRate,
						channels: audioChannels,
						bitsPerSample: audioBitsPerSample
					});

					const byteArray = Uint8Array.from(atob(audioContent), c => c.charCodeAt(0));
					audioChunks.push(byteArray);

					if (isFinal) {
						console.log('[wait_for_responses] Final audio chunk, merging...');
						audioResponse = audioContent;
						
						const totalLength = audioChunks.reduce((sum, chunk) => sum + chunk.length, 0);
						console.log('[wait_for_responses] Total audio size:', totalLength);
						console.log('[wait_for_responses] Audio format:', audioFormat);
						
						let offset = 0;
						const mergedArray = new Uint8Array(totalLength);
						for (const chunk of audioChunks) {
							mergedArray.set(chunk, offset);
							offset += chunk.length;
						}
						
						// æ£€æŸ¥æ˜¯å¦éœ€è¦æ·»åŠ  WAV å¤´
						let finalAudioData = mergedArray;
						let mimeType = `audio/${audioFormat}`;
						
						// æ£€æŸ¥æ˜¯å¦å·²ç»æœ‰ WAV æ–‡ä»¶å¤´ (æ£€æŸ¥å‰4ä¸ªå­—èŠ‚æ˜¯å¦ä¸º "RIFF")
						const hasWavHeader = mergedArray.length >= 4 && 
							mergedArray[0] === 0x52 && // 'R'
							mergedArray[1] === 0x49 && // 'I'
							mergedArray[2] === 0x46 && // 'F'
							mergedArray[3] === 0x46;   // 'F'
						
						console.log('[wait_for_responses] Has WAV header:', hasWavHeader);
						
						// å¦‚æœå·²ç»æœ‰ WAV å¤´ï¼Œä»å¤´éƒ¨è¯»å–çœŸå®çš„éŸ³é¢‘å‚æ•°
						if (hasWavHeader) {
							const view = new DataView(mergedArray.buffer, mergedArray.byteOffset);
							const extractedChannels = view.getUint16(22, true);
							const extractedSampleRate = view.getUint32(24, true);
							const extractedBitsPerSample = view.getUint16(34, true);
							
							console.log('[wait_for_responses] â„¹ Found existing WAV header, extracted params:', {
								sampleRate: extractedSampleRate,
								channels: extractedChannels,
								bitsPerSample: extractedBitsPerSample
							});
							
							// ä½¿ç”¨ä» WAV å¤´æå–çš„å‚æ•°ï¼ˆæ›´å‡†ç¡®ï¼‰
							audioSampleRate = extractedSampleRate;
							audioChannels = extractedChannels;
							audioBitsPerSample = extractedBitsPerSample;
						}
						
						if (audioFormat === 'wav' && !hasWavHeader) {
							console.log('[wait_for_responses] âš  WAV format but no header detected, adding WAV header...');
							console.log('[wait_for_responses] Using audio params:', {
								sampleRate: audioSampleRate,
								channels: audioChannels,
								bitsPerSample: audioBitsPerSample
							});
							console.log('[wait_for_responses] Input data size:', mergedArray.length);
							// ä½¿ç”¨ä»æœåŠ¡å™¨è·å–çš„çœŸå®å‚æ•°æ·»åŠ  WAV æ–‡ä»¶å¤´
							finalAudioData = addWavHeader(mergedArray, audioSampleRate, audioChannels, audioBitsPerSample);
							mimeType = 'audio/wav';
							console.log('[wait_for_responses] âœ“ WAV header added, new size:', finalAudioData.length, 'diff:', finalAudioData.length - mergedArray.length);
						} else {
							console.log('[wait_for_responses] â„¹ Using original audio data without adding header');
						}
						
						const completeAudioBlob = new Blob([finalAudioData], { type: mimeType });
						console.log('[wait_for_responses] Audio blob created, calculating duration...');
						console.log('[wait_for_responses] Blob size:', completeAudioBlob.size, 'MIME type:', mimeType);
						
						// è®¡ç®—ç†è®ºæ—¶é•¿ï¼ˆç”¨äºå¯¹æ¯”ï¼‰
						const bytesPerSecond = audioSampleRate * audioChannels * (audioBitsPerSample / 8);
						const theoreticalDuration = (finalAudioData.length - 44) / bytesPerSecond; // å‡å» WAV å¤´
						console.log('[wait_for_responses] Theoretical duration:', theoreticalDuration.toFixed(2), 's');
						
						const duration = await getAudioDuration(completeAudioBlob, audioSampleRate, audioChannels, audioBitsPerSample);
						console.log('[wait_for_responses] Actual duration:', duration, 's');
						
						// å°†ç§’è½¬æ¢ä¸ºæ¯«ç§’
						const durationMs = duration * 1000;
						console.log('[wait_for_responses] Duration in ms:', durationMs);
						
						addMessage("assistant", durationMs, completeAudioBlob);
						console.log(`[wait_for_responses] âœ“ Complete: ${audioChunks.length} chunks, ${duration.toFixed(2)}s (${durationMs.toFixed(0)}ms)`);
						
						break;
					}
				}
			} else if (response.type === "error") {
				const errorData = response.data || {};
				console.error('[wait_for_responses] âœ— Error response:', errorData);
				break;
			}
		} catch (err) {
			if (err.message === 'Timeout') {
				console.warn("\nâš  Timeout waiting for response");
			} else {
				console.error(`\nâœ— Error receiving response:`, err);
			}
			break;
		}
	}

	return { textResponse, audioResponse };
}

async function handleResponse(audioBlob) {
	try {
		console.log('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');
		console.log('[handleResponse] ğŸš€ START');
		console.log('[handleResponse] Received audio blob:', audioBlob.size, 'bytes');
		
		// Generate ONE requestId for the entire workflow
		const requestId = `req_${Date.now()}`;
		console.log('[handleResponse] Generated request ID:', requestId);
		console.log('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');
		
		// Send audio with the requestId
		console.log('\n[handleResponse] â–¶ STEP 1a: Sending audio...');
		await sendAudio(audioBlob, requestId);
		console.log('[handleResponse] âœ“ STEP 1a completed');
		
		// Send image with the SAME requestId
		console.log('\n[handleResponse] â–¶ STEP 1b: Sending image...');
		await sendImageMessage(requestId);
		console.log('[handleResponse] âœ“ STEP 1b completed');
		
		// Complete input with the SAME requestId - MUST wait for completion!
		console.log('\n[handleResponse] â–¶ STEP 2: Completing input...');
		await completeInput(requestId);
		console.log('[handleResponse] âœ“ STEP 2 completed');
		
		// Wait for responses with the SAME requestId
		console.log('\n[handleResponse] â–¶ STEP 3: Waiting for responses...');
		await wait_for_responses(requestId);
		console.log('[handleResponse] âœ“ STEP 3 completed');
		
		console.log('\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');
		console.log('[handleResponse] ğŸ‰ ALL STEPS COMPLETED');
		console.log('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n');
	} catch (err) {
		console.error('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');
		console.error('[handleResponse] âŒ FAILED at some step');
		console.error('[handleResponse] Error:', err);
		console.error('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');
	}
}

onMounted(async () => {
	audioContext = new (window.AudioContext || window.webkitAudioContext)();
	await parseHashImage();

	// Connect to WebSocket and wait for connection to be ready
	try {
		await connectWS();
		console.log('[onMounted] âœ“ WebSocket connection established');
	} catch (error) {
		console.error('[onMounted] âŒ WebSocket connection failed:', error);
		connectionError.value = connectionError.value || 'Failed to connect. Please refresh the page.';
	}

	initRecorder();

	// Auto-focus on talk button for accessibility (first in tab order)
	nextTick(() => {
		talkButtonRef.value?.focus();
	});
})

onUnmounted(() => {
	stopCurrentAudio(); 
	ws?.close(); 
	if (mediaRecorder && mediaRecorder.state !== 'inactive') mediaRecorder.stop();
	mediaStream?.getTracks().forEach(t => t.stop()); 
	audioContext?.close();
})
</script>

<style scoped>

.container {
	width: 100vw;
	height: 100vh;
	display: flex;
	flex-direction: column;
	align-items: center;
	overflow: hidden; /* é˜²æ­¢æ•´ä¸ªé¡µé¢æ»šåŠ¨ */
	position: fixed; /* å›ºå®šåœ¨è§†å£ */
	top: 0;
	left: 0;
}

/* é¡µé¢æŒ‡ç¤ºå™¨ - åœ¨TopNavä¸­æ˜¾ç¤º */
.page-indicator {
	font-size: 15px;
	font-weight: 600;
	color: #5f6368;
}

/* è¿”å›æŒ‰é’® - å·¦ä¸Šè§’ç®­å¤´ */
.back-btn-corner {
	position: absolute;
	top: 10px;
	left: 10px;
	z-index: 10;
	display: flex;
	align-items: center;
	justify-content: center;
	width: 40px;
	height: 40px;
	padding: 0;
	background: rgba(255, 255, 255, 0.15);
	color: white;
	border: none;
	border-radius: 50%;
	cursor: pointer;
	transition: all 0.3s ease;
}

.back-btn-corner:hover {
	background: rgba(255, 255, 255, 0.25);
	transform: scale(1.1);
}

.back-btn-corner:focus {
	outline: 2px solid white;
	outline-offset: 2px;
}

.content {
	position: relative;
	display: flex;
	flex-direction: column;
	width: 50%;
	height: calc(100vh - 64px); /* å‡å»é¡¶éƒ¨å¯¼èˆªæ é«˜åº¦ */
	margin-top: 64px; /* ä¸ºé¡¶éƒ¨å¯¼èˆªæ ç•™å‡ºç©ºé—´ */
	background-color: black;
	overflow: hidden; /* é˜²æ­¢å†…å®¹æº¢å‡º */
}

/* å›ºå®šçš„å›¾ç‰‡åŒºåŸŸ */
.target-image {
	flex-shrink: 0; /* é˜²æ­¢è¢«å‹ç¼© */
	margin-top: 2vh;
	margin-bottom: 0;
	padding-bottom: 2vh;
	display: flex;
	justify-content: center;
	align-items: center;
	width: 100%;
	background-color: black;
	border-bottom: 1px solid #333; /* æ·»åŠ åˆ†éš”çº¿ */
}

.target-image img {
	max-height: 25vh; /* å›¾ç‰‡æœ€å¤§é«˜åº¦ */
	max-width: 70%;
	width: auto;
	height: auto;
	object-fit: contain;
}

/* å¯æ»šåŠ¨çš„èŠå¤©åŒºåŸŸ */
.chat-area {
	width: 100%;
	flex: 1; /* å æ®å‰©ä½™ç©ºé—´ */
	overflow-y: auto; /* å¯ç”¨å‚ç›´æ»šåŠ¨ */
	overflow-x: hidden; /* ç¦æ­¢æ¨ªå‘æ»šåŠ¨ */
	padding: 20px 10px; /* æ·»åŠ ä¸Šä¸‹å†…è¾¹è· */
	box-sizing: border-box;
	position: relative;
}

/* è‡ªå®šä¹‰æ»šåŠ¨æ¡æ ·å¼ï¼ˆå¯é€‰ï¼Œç¾åŒ–æ»šåŠ¨æ¡ï¼‰ */
.chat-area::-webkit-scrollbar {
	width: 8px;
}

.chat-area::-webkit-scrollbar-track {
	background: #1a1a1a;
}

.chat-area::-webkit-scrollbar-thumb {
	background: #444;
	border-radius: 4px;
}

.chat-area::-webkit-scrollbar-thumb:hover {
	background: #666;
}

.control-area {
	width: 100%;
	height: 20%; /* å æ® 20% é«˜åº¦ */
	display: flex;
	flex-direction: column;
	align-items: center;
	justify-content: center;
	flex-shrink: 0; /* é˜²æ­¢è¢«å‹ç¼© */
	border-top: 1px solid #333; /* æ·»åŠ åˆ†éš”çº¿ï¼ˆå¯é€‰ï¼‰ */
}

.connection-error {
	color: #ff6b6b;
	font-size: 14px;
	margin-bottom: 10px;
	text-align: center;
	padding: 8px 16px;
	background-color: rgba(255, 107, 107, 0.1);
	border-radius: 6px;
	border: 1px solid rgba(255, 107, 107, 0.3);
}

.talk-button {
	padding: 15px 40px;
	font-size: 16px;
	font-weight: 500;
	border-radius: 8px;
	border: 2px solid #646cff;
	background-color: #1a1a1a;
	color: white;
	cursor: pointer;
	transition: all 0.3s ease;
	user-select: none; /* é˜²æ­¢æ–‡å­—è¢«é€‰ä¸­ */
}

.talk-button:disabled {
	opacity: 0.5;
	cursor: not-allowed;
	border-color: #444;
	background-color: #0a0a0a;
}

.talk-button:not(:disabled):hover {
	background-color: #2a2a2a;
	border-color: #747bff;
}

.talk-button:focus {
	outline: 2px solid #646cff;
	outline-offset: 2px;
}

/* æŒ‰ä¸‹æ—¶çš„æ·¡è“è‰²æ ·å¼ */
.talk-button.is-recording {
	background-color: #87CEEB; /* æ·¡è“è‰² (Sky Blue) */
	border-color: #4682B4; /* æ·±ä¸€ç‚¹çš„è“è‰²è¾¹æ¡† */
	color: #1a1a1a; /* æ·±è‰²æ–‡å­—ä»¥æé«˜å¯¹æ¯”åº¦ */
	transform: scale(0.98); /* è½»å¾®ç¼©å°æ•ˆæœ */
}

/* ä¹Ÿå¯ä»¥ä½¿ç”¨ :active ä¼ªç±»ä½œä¸ºå¤‡ç”¨ */
.talk-button:active {
	transform: scale(0.98);
}

/* AI æè¿°åŒºåŸŸæ ·å¼ */
.ai-description-box {
	margin: 0 auto 20px auto;
	padding: 16px 18px;
	max-width: 80%;
	background: linear-gradient(135deg, #e0f2fe 0%, #bae6fd 100%);
	border-left: 5px solid #0ea5e9;
	border-radius: 10px;
	box-shadow: 0 3px 12px rgba(14, 165, 233, 0.2);
}

.ai-description-box .ai-badge {
	display: inline-block;
	padding: 6px 14px;
	background: linear-gradient(135deg, #0ea5e9 0%, #0284c7 100%);
	color: white;
	border-radius: 20px;
	font-size: 0.85rem;
	font-weight: 700;
	margin-bottom: 10px;
	box-shadow: 0 2px 6px rgba(14, 165, 233, 0.4);
}

.ai-description-text {
	color: #0c4a6e;
	font-size: 0.95rem;
	line-height: 1.7;
	margin: 0;
	word-wrap: break-word;
}

/* ============= ç§»åŠ¨ç«¯é€‚é… ============= */
@media (max-width: 768px) {
	.container {
		padding: 8px;
		height: 100vh;
		height: 100dvh; /* åŠ¨æ€è§†å£é«˜åº¦ï¼Œé€‚é…ç§»åŠ¨ç«¯åœ°å€æ  */
	}

	.content {
		border-radius: 12px;
	}

	.target-image {
		height: 20vh; /* ç§»åŠ¨ç«¯å‡å°‘å›¾ç‰‡åŒºåŸŸé«˜åº¦ */
		padding: 8px;
	}

	.target-image img {
		max-height: 18vh;
		max-width: 85%;
	}

	.chat-area {
		padding: 12px 8px;
		font-size: 0.9rem;
	}

	.control-area {
		height: 15vh; /* ç§»åŠ¨ç«¯å‡å°‘æ§åˆ¶åŒºåŸŸé«˜åº¦ */
		padding: 8px;
	}

	.talk-button {
		font-size: 1rem;
		padding: 12px 24px;
		min-width: 140px;
		min-height: 44px; /* ç§»åŠ¨ç«¯æ¨èçš„æœ€å°ç‚¹å‡»åŒºåŸŸ */
	}

	.ai-description-box {
		margin-bottom: 12px;
		padding: 12px;
	}

	.ai-badge {
		font-size: 0.8rem;
		padding: 4px 10px;
	}

	.ai-description-text {
		font-size: 0.9rem;
		line-height: 1.6;
	}
}

@media (max-width: 480px) {
	.container {
		padding: 4px;
	}

	.target-image {
		height: 18vh;
		padding: 4px;
	}

	.target-image img {
		max-height: 16vh;
		max-width: 90%;
	}

	.chat-area {
		padding: 8px 4px;
		font-size: 0.85rem;
	}

	.control-area {
		height: 12vh;
		padding: 4px;
	}

	.talk-button {
		font-size: 0.9rem;
		padding: 10px 20px;
		min-width: 120px;
		min-height: 40px;
	}

	.ai-description-box {
		margin-bottom: 8px;
		padding: 8px;
	}

	.ai-badge {
		font-size: 0.75rem;
		padding: 3px 8px;
	}

	.ai-description-text {
		font-size: 0.85rem;
		line-height: 1.5;
	}
}
</style>
